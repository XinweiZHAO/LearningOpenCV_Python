{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LearningOpenCV-Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2  # 导入cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Core Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Basic Operations on Images\n",
    "1. 获取像素值并修改\n",
    "2. 获取图像属性\n",
    "3. 设置Region of Image(ROI)\n",
    "4. 拆分与合并图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1. Accessing and Modifying pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../Ch2_Gui_Features/input/Oec.jpeg') # ../ 至上一目录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过像素坐标获取像素值，返回BGR list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202 182 104]\n"
     ]
    }
   ],
   "source": [
    "px = img[100, 100]\n",
    "print(px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取蓝色通道像素值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "blue = img[100,100,0] # BGR -> 0, 1, 2\n",
    "print blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改像素值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "img[100, 100] = [255, 255, 255] # 原处修改\n",
    "print(img[100, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Better pixel accessing and editing method :**\n",
    "\n",
    "numpy的 `array.item()` 和 `array.itemset()` 函数对处理单一像素性能更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.item(10,10,2) # 获取红色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.itemset((10,10,2),100) # 修改像素值\n",
    "img.item(10,10,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Accessing Image Properties\n",
    "\n",
    "img存为Numpy array，需要使用相关Numpy API：[Numpy Manual](http://docs.scipy.org/doc/numpy/)\n",
    "\n",
    "图像（numpy array）属性包括：像素行列数，通道，图像数据类型，pixel数量......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1197L, 1800L, 3L)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape) # 如果时grayscale图像则只返回像素行列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6463800\n"
     ]
    }
   ],
   "source": [
    "print(img.size) # number of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(img.dtype) # image datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Image ROI\n",
    "\n",
    "有时候，你将不得不与图像的特定区域打交道。对于人眼检测而言，在图像上首先应执行面部检测，直至图像中的脸部被发现，然后再在该脸部区域内搜索眼睛。这种方法可以提高精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fish = img[20:200, 330:500] # numpy slicing\n",
    "cv2.namedWindow('img', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('img',fish)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Splitting and Merging Image Channels \n",
    "\n",
    "BGR通道可以拆分为三个独立的通道（拆出3个颜色通道），而三个通道又可以合并到一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b, g, r = cv2.split(img)\n",
    "img = cv2.merge((b,g,r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者以："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b, g, r = img[:,:,0], img[:,:,1], img[:,:,2] # 使用更高效的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img[:,:,2] = 0 # 设置红色通道array均为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Making Borders for Images (Padding)\n",
    "\n",
    "使用`cv2.copyMakeBoder()`函数（此外该函数可以做convolution operation, zero padding）\n",
    "\n",
    "主要参数：\n",
    "- **src** - 输入图形img\n",
    "- **top, bottom, left, right** - 对应方向的边界宽度，以pixel定义\n",
    "- **borderType** - 定义添加的边界类型，可以是以下各类:\n",
    "  - **cv2.BORDER_CONSTANT** - Adds a constant colored border. The value should be given as next argument.\n",
    "  - **cv2.BORDER_REFLECT** - Border will be mirror reflection of the border elements, like this : fedcba|abcdefgh|hgfedcb\n",
    "  - **cv2.BORDER_REFLECT_101** or **cv2.BORDER_DEFAULT** - Same as above, but with a slight change, like this : gfedcb|abcdefgh|gfedcba\n",
    "  - **cv2.BORDER_REPLICATE** - Last element is replicated throughout, like this: aaaaaa|abcdefgh|hhhhhhh\n",
    "  - **cv2.BORDER_WRAP** - Can’t explain, it will look like this : cdefgh|abcdefgh|abcdefg\n",
    "- value - 边界颜色（若边界类型为cv2.BORDER_CONSTANT）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BLUE = [255,0,0]\n",
    "img1 = cv2.imread('./input/opencv_logo.png')\n",
    "replicate = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REPLICATE)\n",
    "reflect = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT)\n",
    "reflect101 = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT_101)\n",
    "wrap = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_WRAP)\n",
    "constant= cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_CONSTANT,value=BLUE)\n",
    "plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')\n",
    "plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')\n",
    "plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')\n",
    "plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')\n",
    "plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')\n",
    "plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')\n",
    "plt.show() # Image is displayed with matplotlib. So RED and BLUE planes will be interchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Arithmetic Operations on Images Goal\n",
    "1. 学习若干简单图像计算算法，如：加，减，按位计算等等\n",
    "2. 函数cv2.add(); cv2.addWeighted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Image Addition\n",
    "采用 `cv2.add()` 或者 `res = img1 + img2` 方式，但要注意：\n",
    ">OpenCV addition is a saturated operation while Numpy addition is a modulo operation.\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255]]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "x = np.uint8([250])\n",
    "y = np.uint8([10])\n",
    "print(cv2.add(x, y)) # 250+10 = 260 => 255\n",
    "print(x + y) # 250+10 = 260 - 256 = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Image Blending\n",
    ">图像合成计算公式：$g(x)=(1-\\alpha)f_0(x)+ \\alpha f_1(x) + \\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./input/ml.jpg')\n",
    "img2 = cv2.imread('./input/opencv_logo.png') # 两张图的像素行列要一样(90x90像素)\n",
    "dst = cv2.addWeighted(img1, 0.7, img2, 0.3, 0)\n",
    "# cv2.namedWindow('dst',cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 3. Bitwise Operations\n",
    "包括 `AND`; `OR`; `NOT` 以及` XOR`操作\n",
    "\n",
    "在提取图像的任何部分区域时（我们将在接下来的章节中看到的）他们将是非常有用的，例如定义和使用非矩形ROI。\n",
    "\n",
    "**以下例子将展示如何改变图像的特定区域：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "我希望实现将OpenCV的标志放置在某张图像的上方。如果我通过add方法处理两个图像，这会改变显示的色彩。但如果我将其融入到image中，则会有一个透明的效果。但我不希望它是透明的。如果这是一个矩形区域，我可以用前述的ROI来处理。但是OpenCV的标志不是一个矩形，而是非规则的。所以，你可以用如下的按位运算来做到这一点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load two images\n",
    "img1 = cv2.imread('./input/messi5.jpg')\n",
    "img2 = cv2.imread('./input/opencv_logo.png')\n",
    "# I want to put logo on top-left corner, So I create a ROI\n",
    "rows,cols,channels = img2.shape\n",
    "roi = img1[0:rows, 0:cols ]\n",
    "# Now create a mask of logo and create its inverse mask also\n",
    "img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY) # 将image转为灰度图\n",
    "cv2.imshow('img2gray',img2gray)\n",
    "# ----------------------\n",
    "ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY) # 阈值选区\n",
    "cv2.imshow('mask',mask)\n",
    "# ----------------------\n",
    "mask_inv = cv2.bitwise_not(mask) # 反选处logo(即logo区变白)\n",
    "# ----------------------\n",
    "cv2.imshow('mask_inv',mask_inv)\n",
    "# Now black-out the area of logo in ROI\n",
    "img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "# Take only region of logo from logo image.\n",
    "img2_fg = cv2.bitwise_and(img2,img2,mask = mask)\n",
    "# Put logo in ROI and modify the main image\n",
    "dst = cv2.add(img1_bg,img2_fg)\n",
    "img1[0:rows, 0:cols ] = dst\n",
    "cv2.imshow('res',img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.3.3 Performance Measurement and Improvement Techniques\n",
    "**在图像处理，因为你需要每秒处理大量的运算。强制性要求：你的代码不仅能提供正确的解决方案，而且在以最快的速度运行。**\n",
    "1. 评估代码性能\n",
    "2. 对于提高性能的一些建议\n",
    "3. 主要函数 `cv2.getTickCount`；`cv2.getTickFrequency`\n",
    "\n",
    "此外Python也提供了 **time** 模块，对于评估代码运行速度也是有帮助的，**profile**模块则提供了代码的详细报告，如每个函数所消耗的时间，函数被调用的次数等等。但是如果你使用Ipython，那么这些功能都集成在用户友好操作中了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1. Measuring Performance with OpenCV\n",
    "- `cv2.getTickCount()`  函数返回时钟周期的数目，reference events（如机器被接通）的发生到此函数被调用时刻的计数值。\n",
    "- `cv2.getTickFrequency` 函数返回时钟频率，或者是每秒多少个时钟周期，所以要想了解执行时间你可以这么做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8683665901e-05\n"
     ]
    }
   ],
   "source": [
    "e1 = cv2.getTickCount()\n",
    "# your code execution\n",
    "e2 = cv2.getTickCount()\n",
    "time = (e2 - e1)/cv2.getTickFrequency()\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62684235893\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('./input/messi5.jpg')\n",
    "e1 = cv2.getTickCount()\n",
    "for i in xrange(5,49,2):\n",
    "    img1 = cv2.medianBlur(img1,i) # 运用中值滤波\n",
    "e2 = cv2.getTickCount()\n",
    "t = (e2 - e1)/cv2.getTickFrequency()\n",
    "print(t)\n",
    "cv2.imshow('res',img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2. Default Optimization in OpenCV\n",
    "许多OpenCV的函数是使用SSE2，AVX等优化过的。其中也包含了一些未优化过的代码。OpenCV会自动运行优化过的代码如果使能的话。\n",
    "- `cv2.useOptimized()` ：检测是否打开优化\n",
    "- `cv2.setUseOptimized()` ：使能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if optimization is enabled\n",
    "cv2.useOptimized() # enabled by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 25.7 ms per loop\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./input/messi5.jpg')\n",
    "%timeit res = cv2.medianBlur(img,49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disable Optimization："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cv2.setUseOptimized(False) # Disable it'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''cv2.setUseOptimized(False) # Disable it'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 16.4 µs per loop\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./input/messi5.jpg')\n",
    "# optimized median filtering is almost ~2x faster than unoptimized version\n",
    "%timeit res = cv2.medianBlur(img,49) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Measuring Performance in IPython\n",
    "Ipython提供 `%timeit` ，多次运行代码以评估平均运行时间。同样的，其适用于单行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 loops, best of 3: 54.3 ns per loop\n"
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "%timeit y=x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 loops, best of 3: 51.2 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit y=x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 39.90 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000000 loops, best of 3: 544 ns per loop\n"
     ]
    }
   ],
   "source": [
    "z = np.uint8([5])\n",
    "%timeit y=z*z # Python scalar operations are faster than Numpy scalar operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 24.48 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000000 loops, best of 3: 613 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit y=np.square(z) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the performance of `cv2.countNonZero()` and `np.count_nonzero()` for same image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 12.5 µs per loop\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./input/messi5.jpg', 0) # grayscale\n",
    "%timeit z = cv2.countNonZero(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 366 µs per loop\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./input/messi5.jpg', 0) # grayscale\n",
    "%timeit z = np.count_nonzero(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常情况下，OpenCV函数比numpy的函数更快。因此，对于相同的操作，**OpenCV函数是优选的**。但是，也有例外，尤其是Numpy以**view**方式工作而非copies（复制原数据）。\n",
    "\n",
    "**以下为注意点：**\n",
    "1. **Avoid using loops** in Python as far as possible, especially double/triple loops etc. They are inherently slow.\n",
    "2. Vectorize the algorithm/code to the maximum possible extent because **Numpy and OpenCV are optimized for\n",
    "vector operations**.\n",
    "3. Exploit the cache coherence.\n",
    "4. **Never make copies of array** unless it is needed. Try to use views instead. Array copying is a costly operation.\n",
    "\n",
    "Even after doing all these operations, if your code is still slow, or use of large loops are inevitable, use additional\n",
    "libraries like **Cython** to make it faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4 Mathematical Tools in OpenCV\n",
    "主成分分析(**PCA**)与奇异值分解(**SVD**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Image Processing in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Changing Colorspaces\n",
    "1. 如何进行图像色彩空间转换，BGR；Gray；HSV\n",
    "2. 创建应用程序，在视频中提取一个彩色的对象\n",
    "3. 函数`cv2.cvtColor()`；`cv2.inRange()` 等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Changing Color-space\n",
    "OpenCV中有超过150个可用的色彩空间转换方法\n",
    "```Python\n",
    "cv2.cvtColor(input_img, flag)  # flag determines the type of conversion.\n",
    "```\n",
    "对于**HSV**：Hue：[0,179]；  Saturation：[0,255] and Value： [0,255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "# print(flags) # 所有可用转化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Object Tracking\n",
    "现在我们知道如何将BGR图片转为HSV色彩空间，我们可以利用这个来提取颜色对象。在表示一个颜色上，HSV相对RGB要来的简单。在这里我们提取一个蓝色目标。打开摄像头后可以拿一个蓝色物体在拍摄区域内以验证程序。\n",
    "\n",
    "**Extract a colored object：**\n",
    "- 提取视频帧\n",
    "- 将提取的图片从RGB转为HSV\n",
    "- 通过提供一个蓝色值的范围来对图像做阈值（We threshold the HSV image for a range of blue color）\n",
    "- 现在我们可以提取出这个蓝色对象，然后可以做任何想做的事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(1):\n",
    "    # Take each frame\n",
    "    _, frame = cap.read()\n",
    "    # Convert BGR to HSV\n",
    "    img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv2.inRange(img_hsv, lower_blue, upper_blue)\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask = mask)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27: # Esc key\n",
    "        break\n",
    "cap.release() # release不可忘\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How to find HSV values to track?\n",
    "既可以利用 `cv2.cvtColor` 将RGB颜色转为HSV,然后再利用转换后的颜色来提取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 60 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "green = np.uint8([[[0,255,0 ]]])\n",
    "hsv_green = cv2.cvtColor(green,cv2.COLOR_BGR2HSV) # find the HSV value of Green\n",
    "print(hsv_green)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Image Thresholding\n",
    "**学会简单阈值，自适应阈值(Adaptive thresholding)，大津阈值(Otsu’s thresholding)等等。**\n",
    "\n",
    "主要函数: `cv2.threshold()和cv2.adaptiveThreshold()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Simple Thresholding\n",
    "图像阈值处理比较直白：如果像素值大于阈值时，它被重置为一个值（可以是white），否则它被赋予另一个值（可能是black）\n",
    "- `cv2.threshold()`函数 :\n",
    "  - 输入参数：\n",
    "    - 第一参数：img，a grayscale image\n",
    "    - 第二参数：阈值，用于分类像素值\n",
    "    - 第三参数maxVal，当像素值超过（sometimes less than）阈值时对该像素赋的值\n",
    "    - 第四参数，代表不同的thresholding类型:\n",
    "      - cv2.THRESH_BINARY\n",
    "      - cv2.THRESH_BINARY_INV\n",
    "      - cv2.THRESH_TRUNC\n",
    "      - cv2.THRESH_TOZERO\n",
    "      - cv2.THRESH_TOZERO_INV\n",
    "  - 输出参数：\n",
    "    - retval\n",
    "    - thresholded image\n",
    "    \n",
    "**代码：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/gradient.jpg',0)\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "for i in xrange(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Adaptive Thresholding\n",
    "在前面的阈值方法中我们采用一个全局值（global value）作为唯一的阈值。\n",
    ">get different thresholds for different regions of the same image and it gives us better results for images with varying illumination（光照）.\n",
    "\n",
    "```Python\n",
    "Docstring: adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) -> dst\n",
    "```\n",
    "参数：\n",
    "- **Adaptive Method **- It decides how thresholding value is calculated.\n",
    "  - cv2.ADAPTIVE_THRESH_MEAN_C : threshold value is the mean of neighbourhood area.\n",
    "  - cv2.ADAPTIVE_THRESH_GAUSSIAN_C : threshold value is the weighted sum of neighbourhood values where weights are a gaussian window.\n",
    "- **Block Size** - It decides the size of neighbourhood area.\n",
    "\n",
    "- **C **- It is just a constant which is subtracted from the mean or weighted mean calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compares global thresholding and adaptive thresholding \n",
    "img = cv2.imread('./input/dave.jpg',0)\n",
    "img = cv2.medianBlur(img,5)\n",
    "\n",
    "ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "\n",
    "for i in xrange(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Otsu’s Binarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们使用大律阈值时就需要用到前面提到的阈值函数返回值**`retVal`**。在全局阈值法（global thresholding,即1. Simple Thresholding）中，我们采用了一个随机值来定义这个全局阈值，但我们不能确是好是坏，方法是不断地尝试。但是对于一个双峰图片（**bimodal image** , it's histogram has two peaks），我们则可以近似采用一个双峰的中间值。这就是大律法的处理方法。所以简单地说该方法自动基于图片双峰计算这个阈值（当然对于非双峰图片，则该方法不会准确）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里我们仍使用 ` cv2.threshold` 这个函数，但需要传入一个额外的标志 - `cv2.THRESH_OTSU`。**而对于阈值则简单传入一个0即可**。然后算法会自动计算并将最优阈值返回到**`retVal`**。如果大律阈值没有被使用，则**`retVal`**为你最初传入的那个简单阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/noisy2.png',0)\n",
    "\n",
    "# global thresholding\n",
    "ret1,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# plot all the images and their histograms\n",
    "images = [img, 0, th1,\n",
    "          img, 0, th2,\n",
    "          blur, 0, th3]\n",
    "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
    "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
    "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    "\n",
    "for i in xrange(3):\n",
    "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 Geometric Transformations of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/messi5.jpg')\n",
    "res = cv2.resize(img, None, fx=2, fy=2, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('res',res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 或者通过如下方法：\n",
    "height, width = img.shape[:2]\n",
    "res = cv2.resize(img,(2*width, 2*height), interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('res',res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/messi5.jpg',0)\n",
    "rows,cols = img.shape\n",
    "# define Translation Matrix = \n",
    "#   [ 1 0 tx \n",
    "#     0 1 ty ]\n",
    "M = np.float32([[1,0,200],[0,1,50]]) # 水平方向200 垂直方向50\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "cv2.imshow('img',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/messi5.jpg',0)\n",
    "rows,cols = img.shape\n",
    "# 获得变换矩阵\n",
    "M = cv2.getRotationMatrix2D((cols/2,rows/2),60,0.6) # 给定：center旋转中心, angle旋转角, scale缩放系数\n",
    "# 实施变换\n",
    "dst = cv2.warpAffine(img, M, (cols,rows)) # image, 变换Matrix, 图像size\n",
    "cv2.imshow('Rotateimg',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Affine Transformation (仿射变换)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/drawing.png')\n",
    "rows,cols,ch = img.shape\n",
    "# 变换对应3个点\n",
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    "# 获得变换矩阵\n",
    "M = cv2.getAffineTransform(pts1,pts2)\n",
    "# 实施变换\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Perspective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/sudokusmall.png')\n",
    "rows,cols,ch = img.shape\n",
    "# 定义变换对应的4个点\n",
    "pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "# 获得变换矩阵\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "# 实施变换\n",
    "dst = cv2.warpPerspective(img,M,(400,400))\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.4 Smoothing Images（图像平滑/滤波）\n",
    "图像平滑/滤波的目的是消除图像噪声\n",
    "1. 学习图像模糊，各种低通滤波器（邻域均值滤波averaging filtering or low pass filtering）\n",
    "2. 应用定制的过滤器（二维卷积）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 2D Convolution ( Image Filtering )\n",
    "对于一维信号，图像也可以通过利低通滤波器(LPF), 高通滤波器 (HPF)来进行滤波处理。LPF有利于消除噪声或者模糊图像。HPF则有助于发现图像中的一些边界。\n",
    "```Python \n",
    "cv2.filter2D() #  convolve a kernel with an image\n",
    "```\n",
    " 5x5 averaging filter kernel can be defined as follows:\n",
    "$$K =\\frac{1}{25}\\left(\n",
    "\\begin{array}{ccccc}\n",
    " 1 & 1 & 1 & 1 & 1 \\\\\n",
    " 1 & 1 & 1 & 1 & 1 \\\\\n",
    " 1 & 1 & 1 & 1 & 1 \\\\\n",
    " 1 & 1 & 1 & 1 & 1 \\\\\n",
    " 1 & 1 & 1 & 1 & 1 \\\\\n",
    "\\end{array}\n",
    "\\right)$$\n",
    "首先定义一个5x5的框，以图像中某一像素为中心放置该框，落入该框的所有像素值被求和，结果再除以25，以该值作为滤波后该像素的值，然后对图像中的每一像素都这么做。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/opencv_logo.png')\n",
    "# define 5x5 averaging filter kernel\n",
    "kernel = np.ones((5,5),np.float32)/25 \n",
    "# apply averaging filter\n",
    "dst = cv2.filter2D(img,-1,kernel) \n",
    "# plot results\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Image Blurring (Image Smoothing)\n",
    "图像模糊：通过原图与一个LPF卷积来获得。有助于消除噪声。实际上是消除了图像高频信息（例如噪声，边界角点等等），这样会消除图像中的边界信息，当然也有模糊方法其不消除边界信息。OpenCV主要提供了4种模糊技术。\n",
    "1. Averaging\n",
    "$$K = \\frac{1}{9}\\left(\n",
    "\\begin{array}{ccc}\n",
    " 1 & 1 & 1 \\\\\n",
    " 1 & 1 & 1 \\\\\n",
    " 1 & 1 & 1 \\\\\n",
    "\\end{array}\n",
    "\\right)$$\n",
    "\n",
    "通过与归一化的 box filter 卷积：`cv2.blur()` or `cv2.boxFilter()`\n",
    "若不想使用归一化的 box filter 则传入 `normalize=False `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/opencv_logo.png')\n",
    "blur = cv2.blur(img,(5,5))\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Gaussian Filtering\n",
    "\n",
    "对于高斯噪声非常有效，需要定义高斯核：高度、宽度以及x与y方向的标准差，或者也可以采用函数 `cv2.getGaussianKernel()` 生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/opencv_logo.png')\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Median Filtering\n",
    "\n",
    "在核窗口下计算所有像素的中值，然后将中心像素值替换为该值。这是在去除椒盐噪声（随机噪声）非常有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./input/Median Filtering.png')\n",
    "median = cv2.medianBlur(img,7)\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(median),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Bilateral Filtering（双边滤波）\n",
    "前面所述滤波器会消除边界信息，但双边滤波不会。对于消除噪声同时保留边界时是十分有效的。但处理速度相对其他滤波器要慢。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.subplot(121),plt.imshow(img),plt.title('Original')\\nplt.xticks([]), plt.yticks([])\\nplt.subplot(122),plt.imshow(blur),plt.title('Blurred')\\nplt.xticks([]), plt.yticks([])\\nplt.show()\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('./input/bilateral.jpg')\n",
    "blur = cv2.bilateralFilter(img,9,75,75)\n",
    "cv2.imshow('Bilateral Filtering',blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.5 Morphological Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('MorphTrans.png',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "kernel2 = np.ones((8,8),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "erosion2 = cv2.erode(img,kernel2,iterations = 1)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('erosion',erosion)\n",
    "cv2.imshow('erosion2',erosion2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('MorphTrans.png',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "kernel2 = np.ones((8,8),np.uint8)\n",
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "dilation2 = cv2.dilate(img,kernel2,iterations = 1)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('erosion',dilation)\n",
    "cv2.imshow('erosion2',dilation2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Opening(Erosion followed by Dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('opening.png',0)\n",
    "kernel = np.ones((6,6),np.uint8)\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('erosion',opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Closing(Dilation followed by Erosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('closing.png',0)\n",
    "kernel = np.ones((6,6),np.uint8)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('erosion',closing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Morphological Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('MorphTrans.png',0)\n",
    "kernel = np.ones((6,6),np.uint8)\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('erosion',gradient)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  Top Hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('MorphTrans.png',0)\n",
    "kernel = np.ones((12,12),np.uint8)\n",
    "tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('opening',opening)\n",
    "cv2.imshow('erosion',tophat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Black Hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('MorphTrans.png',0)\n",
    "kernel = np.ones((20,20),np.uint8)\n",
    "blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('closing',closing)\n",
    "cv2.imshow('erosion',blackhat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structuring Element\n",
    "need elliptical/circular shaped kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.getStructuringElement(cv2.MORPH_CROSS,(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.4.6 Image Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Sobel and Scharr Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('dave.jpg',0)\n",
    "\n",
    "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')\n",
    "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\n",
    "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Important Matter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('double_edge.jpg',0)\n",
    "# Output dtype = cv2.CV_8U\n",
    "sobelx8u = cv2.Sobel(img,cv2.CV_8U,1,0,ksize=7)\n",
    "# Output dtype = cv2.CV_64F. Then take its absolute and convert to cv2.CV_8U\n",
    "sobelx64f = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=1)\n",
    "abs_sobel64f = np.absolute(sobelx64f)\n",
    "sobel_8u = np.uint8(abs_sobel64f)\n",
    "# Black-to-White transition is taken as Positive slope (it has a positive value) \n",
    "# while White-to-Black transition is taken as a Negative slope (It has negative value). \n",
    "# So when you convert data to np.uint8, all negative slopes are made zero. \n",
    "# CV_8U只有左侧Black-to-White transition一边\n",
    "plt.subplot(1,3,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,3,2),plt.imshow(sobelx8u,cmap = 'gray')\n",
    "plt.title('Sobel CV_8U'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,3,3),plt.imshow(sobel_8u,cmap = 'gray')\n",
    "plt.title('Sobel abs(CV_64F)'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.7 Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('messi5.jpg',0)\n",
    "edges = cv2.Canny(img,100,200, 5, L2gradient = True)\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.8 Image Pyramids\n",
    "1. Gaussian Pyramid  \n",
    "2. Laplacian Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('messi5.jpg')\n",
    "lower_reso = cv2.pyrDown(img)\n",
    "higher_reso = cv2.pyrUp(img)\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('lower_reso',lower_reso)\n",
    "cv2.imshow('higher_reso',higher_reso)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "C:\\builds\\master_PackSlaveAddon-win64-vc12-static\\opencv\\modules\\core\\src\\arithm.cpp:1987: error: (-209) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function cv::arithm_op\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-8cf3b8bbedc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mGE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyrUp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mlpA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# generate Laplacian Pyramid for B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\builds\\master_PackSlaveAddon-win64-vc12-static\\opencv\\modules\\core\\src\\arithm.cpp:1987: error: (-209) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function cv::arithm_op\n"
     ]
    }
   ],
   "source": [
    "A = cv2.imread('apple.jpg')\n",
    "B = cv2.imread('orange.jpg')\n",
    "# generate Gaussian pyramid for A\n",
    "G = A.copy()\n",
    "gpA = [G]\n",
    "for i in xrange(6):\n",
    "    G = cv2.pyrDown(G)\n",
    "    gpA.append(G)\n",
    "# generate Gaussian pyramid for B\n",
    "G = B.copy()\n",
    "gpB = [G]\n",
    "for i in xrange(6):\n",
    "    G = cv2.pyrDown(G)\n",
    "    gpB.append(G)\n",
    "# generate Laplacian Pyramid for A\n",
    "lpA = [gpA[5]]\n",
    "for i in xrange(5,0,-1):\n",
    "    GE = cv2.pyrUp(gpA[i])\n",
    "    L = cv2.subtract(gpA[i-1],GE)\n",
    "    lpA.append(L)\n",
    "# generate Laplacian Pyramid for B\n",
    "lpB = [gpB[5]]\n",
    "for i in xrange(5,0,-1):\n",
    "    GE = cv2.pyrUp(gpB[i])\n",
    "    L = cv2.subtract(gpB[i-1],GE)\n",
    "    lpB.append(L)\n",
    "# Now add left and right halves of images in each level\n",
    "LS = []\n",
    "for la,lb in zip(lpA,lpB):\n",
    "    rows,cols,dpt = la.shape\n",
    "    ls = np.hstack((la[:,0:cols/2], lb[:,cols/2:]))\n",
    "    LS.append(ls)\n",
    "# now reconstruct\n",
    "ls_ = LS[0]\n",
    "for i in xrange(1,6):\n",
    "    ls_ = cv2.pyrUp(ls_)\n",
    "    ls_ = cv2.add(ls_, LS[i])\n",
    "\n",
    "# image with direct connecting each half\n",
    "real = np.hstack((A[:,:cols/2],B[:,cols/2:]))\n",
    "\n",
    "cv2.imwrite('Pyramid_blending2.jpg',ls_)\n",
    "cv2.imwrite('Direct_blending.jpg',real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
